---
title: "ImportandMERGE"
author: "MT"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}


##here is what you would run in terminal to setup an environment like the rstudio environment

#conda create --name RStudio python=3.8
#conda activate RStudio
#conda install pandas matplotlib seaborn scipy statsmodels 
#conda env create -f env_config.yml

#install.packages("reticulate")


library(reticulate)
library(pandoc)


# or for manual setup 
reticulate::use_condaenv("C:/Users/MicrobeJ/anaconda3/envs/RStudio")




# # Set Python path
#use_python(config$python_path)
# 
# # Install Python packages (optional)
# py_install(config$packages)
# 
# 
# reticulate::py_install("pandas")
# reticulate::py_install("matplotlib")
# reticulate::py_install("seaborn")
# reticulate::py_install("scipy")
# reticulate::py_install("statsmodels")





```

```{python}
import pandas as pd
```

## Read Data Master

Here we read in the `data_master` dataset from an Excel file.

```{python}
data_master = pd.read_excel('Data/data_master.xlsx')
```

## Read Trial Data

To read the `trial_data`, we follow a chunking approach. We loop through sets of 3 columns at a time to read in the data and then concatenate these chunks. We also add a 'rep' column to denote the replicate number (1, 2, or 3).

```{python}
# Reading the data in chunks of 3 columns and adding 'rep' column to each chunk
dfs = []
for i in range(1, 4):  # Looping through each set of 3 columns
    cols_to_read = [0, 1, i + 1]  # The columns to read in
    df_chunk = pd.read_csv('Data/trial_data_easier.csv', usecols=cols_to_read, header=None)
    df_chunk.columns = ['unique_id', 'strain', 'titer']
    df_chunk['rep'] = i  # Adding 'rep' column
    dfs.append(df_chunk)

# Concatenating all the chunks into one DataFrame
trial_data_long_corrected = pd.concat(dfs, ignore_index=True)

# Extracting the date from the 'unique_id' column
trial_data_long_corrected['date'] = trial_data_long_corrected['unique_id'].str.split('_').str[0]

# Converting the 'date' column to datetime format
trial_data_long_corrected['date'] = pd.to_datetime(trial_data_long_corrected['date'], format='%m/%d/%Y')

# Adding a 'genotype' column to the trial_data_long_corrected DataFrame
# Mapping the strains to their respective genotypes
strain_to_genotype_mapping = {
    'negative control': 'No Cell Control',
    'LZ22208': 'NA1000',
    'LZ22209': 'NA1000 â–²pilA',
    'LZ22221': 'bNY30a'
}

trial_data_long_corrected['genotype'] = trial_data_long_corrected['strain'].map(strain_to_genotype_mapping)

# Correcting the typo in 'unique_id' and 'date' columns
trial_data_long_corrected.loc[trial_data_long_corrected['unique_id'] == '2/13/2022_AG', 'unique_id'] = '2/13/2023_AG'
trial_data_long_corrected.loc[trial_data_long_corrected['date'] == '2022-02-13', 'date'] = '2023-02-13'





```
## Data Merge

```{python}

# Identify common entries between the two datasets based on 'genotype', 'date', 'rep' and 'titer'
common_entries = pd.merge(data_master, trial_data_long_corrected, 
                          on=['genotype', 'date', 'rep', 'titer'], 
                          how='inner')




```

### Lets finish merging the data manually

```{python}

trial_data_long_corrected.to_excel('Data/trial_data_long_corrected.xlsx', index=False)



```


