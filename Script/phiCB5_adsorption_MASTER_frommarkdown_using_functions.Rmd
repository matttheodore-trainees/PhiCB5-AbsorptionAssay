---
title: "Untitled"
author: "MT"
date: "`r Sys.Date()`"
output: html_document
---

# Data Analysis for PhiCB5 Adsorption Data

## Introduction

The experiment is run in biological replicates (have their own unique id) and technical triplicate for the biological replicates. 
The data set is `data_master_final` from the PhiCB5 adsorption data. This document outlines the statistical tests carried out on the dataset.

#### Data Preparation

The dataset was loaded and the 'unique_id' column was specified as a string to prevent it from being parsed as a date.



We'll use Python for data manipulation, statistical testing, and plotting. The analysis includes:

- Data Import
- Data Normalization
- Summary Statistics
- ANOVA and Tukey's Test
- Plotting

#### Library R

```{r setup, include=FALSE}


##here is what you would run in terminal to setup an environment like the rstudio environment

#conda create --name RStudio python=3.8
#conda activate RStudio
#conda install pandas matplotlib seaborn scipy statsmodels 
#conda env create -f env_config.yml

#install.packages("reticulate")


####### Is this here


# # Set Python path
#use_python(config$python_path)
# 
# # Install Python packages (optional)
# py_install(config$packages)
# 
# 
# reticulate::py_install("pandas")
# reticulate::py_install("matplotlib")
# reticulate::py_install("seaborn")
# reticulate::py_install("scipy")
# reticulate::py_install("statsmodels")

library(reticulate)
library(pandoc)



```

#### Initiate Python Env

```{r, include = FALSE}


reticulate::use_condaenv("C:/Users/MicrobeJ/anaconda3/envs/RStudio")



```

#### Library Python

```{python, include = FALSE}

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import shapiro, levene, f_oneway
from statsmodels.stats.multicomp import pairwise_tukeyhsd

```


Three types of normalization were performed:

1. Direct Subtraction
2. Ratio Normalization
3. Z-Score Normalization






```{python}

# Load the newly uploaded dataset with the 'unique_id' column specified as string
df_new = pd.read_excel("Data/data_master_final.xlsx", dtype={"unique_id": str})

# To check unique values in the 'unique_id' column
print(df_new['unique_id'].unique())


# Calculate the mean titer of the "No Cell Control" for each unique ID
no_cell_control_means_new = df_new[df_new['genotype'] == 'No Cell Control'].groupby('unique_id')['titer'].mean().reset_index()
no_cell_control_means_new.rename(columns={'titer': 'mean_titer_no_cell_control'}, inplace=True)

# Merge this information with the original DataFrame
df_merged_new = pd.merge(df_new, no_cell_control_means_new, on='unique_id', how='left')

# Perform the normalization calculations

# Direct Subtraction
df_merged_new['normalized_titer_direct_sub'] = df_merged_new['titer'] - df_merged_new['mean_titer_no_cell_control']

# Ratio Normalization
df_merged_new['normalized_titer_ratio'] = df_merged_new['titer'] / df_merged_new['mean_titer_no_cell_control']

# Z-Score Normalization
df_merged_new['normalized_titer_zscore'] = (df_merged_new['titer'] - df_merged_new['mean_titer_no_cell_control']) / df_merged_new['mean_titer_no_cell_control'].std()
```



## Plotting the different normalizations

```{python}

# Initialize the figure with modified dimensions for a 2x2 layout
fig, axes = plt.subplots(2, 2, figsize=(20, 20))

# Original Data
sns.violinplot(x='genotype', y='titer', data=df_merged_new, ax=axes[0, 0], inner=None, color='lightgray')
sns.stripplot(x='genotype', y='titer', data=df_merged_new, hue='unique_id', dodge=True, marker='o', alpha=0.7, jitter=True, ax=axes[0, 0])
axes[0, 0].set_title('Original Data')
axes[0, 0].set_xticklabels(axes[0, 0].get_xticklabels(), rotation=45, ha='right')
axes[0, 0].legend().set_visible(False)  # Hide the legend

# Direct Subtraction Normalization
sns.violinplot(x='genotype', y='normalized_titer_direct_sub', data=df_merged_new, ax=axes[0, 1], inner=None, color='lightgray')
sns.stripplot(x='genotype', y='normalized_titer_direct_sub', data=df_merged_new, hue='unique_id', dodge=True, marker='o', alpha=0.7, jitter=True, ax=axes[0, 1])
axes[0, 1].set_title('Direct Subtraction Normalization')
axes[0, 1].set_xticklabels(axes[0, 1].get_xticklabels(), rotation=45, ha='right')
axes[0, 1].legend().set_visible(False)  # Hide the legend

# Ratio Normalization
sns.violinplot(x='genotype', y='normalized_titer_ratio', data=df_merged_new, ax=axes[1, 0], inner=None, color='lightgray')
sns.stripplot(x='genotype', y='normalized_titer_ratio', data=df_merged_new, hue='unique_id', dodge=True, marker='o', alpha=0.7, jitter=True, ax=axes[1, 0])
axes[1, 0].set_title('Ratio Normalization')
axes[1, 0].set_xticklabels(axes[1, 0].get_xticklabels(), rotation=45, ha='right')
axes[1, 0].legend().set_visible(False)  # Hide the legend

# Z-Score Normalization
sns.violinplot(x='genotype', y='normalized_titer_zscore', data=df_merged_new, ax=axes[1, 1], inner=None, color='lightgray')
sns.stripplot(x='genotype', y='normalized_titer_zscore', data=df_merged_new, hue='unique_id', dodge=True, marker='o', alpha=0.7, jitter=True, ax=axes[1, 1])
axes[1, 1].set_title('Z-Score Normalization')
axes[1, 1].set_xticklabels(axes[1, 1].get_xticklabels(), rotation=45, ha='right')
axes[1, 1].legend().set_visible(False)  # Hide the legend

# Add a single legend for all subplots
handles, labels = axes[0, 0].get_legend_handles_labels()
fig.legend(handles, labels, title='Unique ID', loc='upper right')

# Finalize the layout
#plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust the rectangle in which to fit plots
plt.show()


```


## Preliminary Statistical Tests

#### Shapiro-Wilk Test for Normality and Levene's Test for Homogeneity of Variances


**Shapiro-Wilk Test**: The null hypothesis (\(H_0\)) for this test is that the data for each genotype (excluding 'No Cell Control') follows a normal distribution. Rejecting this hypothesis would mean that the data does not follow a normal distribution, which is an assumption for many statistical tests like ANOVA.So first we need to check for normality.

**Levene's Test**: The null hypothesis for the Levene's test is that all genotypes (again, excluding 'No Cell Control') have equal variances. Rejecting this hypothesis would imply that the variances are significantly different, which would violate the assumptions for tests like ANOVA.



```{python}

# Initialize an empty list to store the results of the Shapiro-Wilk test for normality
shapiro_results_list = []

# Loop through each unique_id and genotype to apply the Shapiro-Wilk test
for unique_id in df_merged_new['unique_id'].unique():
    for genotype in df_merged_new['genotype'].unique():
        subset = df_merged_new[(df_merged_new['unique_id'] == unique_id) & (df_merged_new['genotype'] == genotype)]['normalized_titer_direct_sub']
        if len(subset) > 2:  # Shapiro-Wilk test requires at least 3 observations
            stat, p = shapiro(subset)
            shapiro_results_list.append({'unique_id': unique_id, 'genotype': genotype, 'statistic': stat, 'p_value': p})

# Convert the list of dictionaries to a DataFrame
shapiro_results_incl_control = pd.DataFrame(shapiro_results_list)

```


```{python}

# initiate an empty list for Levene's test
levene_results_list = []


# Conduct Levene's test for all normalization methods
levene_test_results = []
for col in ['titer', 'normalized_titer_direct_sub', 'normalized_titer_ratio', 'normalized_titer_zscore']:
    levene_stat, levene_p = levene(*[df_merged_new[df_merged_new['genotype'] == genotype][col] for genotype in df_merged_new['genotype'].unique()])
    levene_test_results.append({'Normalization_Type': col, 'Test_Name': 'Levene', 'P-Value': levene_p})

# Convert the list of dictionaries to a DataFrame
levene_test_df = pd.DataFrame(levene_test_results)

# Display Shapiro and Levene test results
shapiro_results_incl_control, levene_test_df

```

##### Analysis of Tests

1. **Shapiro-Wilk Test**: All genotypes passed the test for normality, supporting the null hypothesis. This allows us to proceed with ANOVA and other parametric tests.


#### now averages of averages for normality and variance

Up until now I believe we have been working with grouping od unique_ids which represent a single bioreplicate of genotypes (meaning all genotype should have 3 or more bioreplicates). 

However,  since we have normalized presumably reducing the day to day variability of the experiment (technical) we may now think about used the mean of genotype, unique id pairings to take the mean of the genotype groupings across the days whichwould yield a single value with a singular standard deviation. Before we do this I believe now we could run levenes test for equal variances across groups (genotypes0 and check for normality of the groups (by genotype) would this make sense and be correct logic?> What would be the cons of this approach and what would be the pros ? 



Pros of This Approach:
Simplification: This would simplify the data structure considerably, making statistical tests less complex and easier to interpret.

Reduced Noise: Normalization followed by averaging would likely reduce both biological and technical noise, making the signal (differences between genotypes) easier to detect.

Statistical Power: With reduced noise and simpler data structure, you might gain statistical power, making it easier to detect real differences between groups.

Cons of This Approach:
Loss of Information: You would be discarding information about the within-group (i.e., within each unique ID) variability. This could be problematic if that variability is of scientific interest.

Assumption of Equal Variance: By reducing the data in this manner, you're implicitly assuming that the variance within each genotype-unique ID pairing is comparable. If this is not the case, the averaged data may be misleading.

Normality: This approach assumes that the mean of each genotype across unique IDs is normally distributed. While this is often a reasonable assumption due to the Central Limit Theorem, it should be empirically tested.

Given these considerations, you could proceed with Levene's test for equal variances and a normality test on the reduced dataset (mean values for each genotype across unique IDs). This would give you a cleaner, simpler dataset to work with while also allowing you to test the necessary assumptions before proceeding to ANOVA.


2. **Levene's Test**: The test for variance homogeneity also passed for all normalization types, again supporting the null hypothesis. This indicates that the variances are not significantly different across the genotypes, meeting the assumption for ANOVA.

Given that the data meet the assumptions of a normal distribution, further statistical tests like the ANOVA or t-tests to compare the means between different genotypes can be performed (parametric testing)


### One-Way ANOVA

```{python}

# One-way ANOVA on original data and all three normalization methods
anova_test_results = []
for col in ['titer', 'normalized_titer_direct_sub', 'normalized_titer_ratio', 'normalized_titer_zscore']:
    f_stat, p_value = f_oneway(*[df_merged_new[df_merged_new['genotype'] == genotype][col].dropna() for genotype in df_merged_new['genotype'].unique()])
    anova_test_results.append({'Normalization_Type': col, 'F-Statistic': f_stat, 'P-Value': p_value})

# Convert the list of dictionaries to a DataFrame
anova_test_df = pd.DataFrame(anova_test_results)

# Tukey's HSD Test on original data and all three normalization methods
tukey_test_results = []
for col in ['titer', 'normalized_titer_direct_sub', 'normalized_titer_ratio', 'normalized_titer_zscore']:
    tukey_result = pairwise_tukeyhsd(df_merged_new[col].dropna(), df_merged_new['genotype'])
    tukey_test_results.append({'Normalization_Type': col, 'Tukey_HSD_Result': tukey_result})

# Convert the list of dictionaries to a DataFrame
tukey_test_df = pd.DataFrame(tukey_test_results)

# Display One-Way ANOVA and Tukey's HSD test results
anova_test_df, tukey_test_df



```


##### Analysis of Tests

**ANOVA**: For all types of titer values (original, direct subtraction normalized, and ratio normalized), the p-values were less than 0.001. This strongly suggests rejecting the null hypothesis, indicating significant differences in means across genotypes.


 **Tukey's HSD**: Similar to ANOVA, the results indicate that there are pairs of genotypes that have significantly different means, leading to the rejection of the null hypothesis for those pairs.
 
 
 









## Interpretations

1. **Original Titer Values**: Significant differences were observed between the genotype NA1000 and the other genotypes (bNY30a, pilAT36C, and No Cell Control). The p-values were below 0.001, suggesting strong evidence against the null hypothesis of equal means.
  
2. **Direct Subtraction Normalized Values**: Similar trends were observed as with the original titer values. The normalization did not drastically change the significance levels between different genotypes.

3. **Ratio Normalized Values**: Again, the normalization seems consistent with the original titer values in terms of statistical significance.

In summary, the statistical tests indicate that the different genotypes have significantly different titer levels. The assumptions for normality and homogeneity of variances were met, allowing for a robust statistical analysis. These findings are consistent across different types of normalization, suggesting that the observed differences are not artifacts of data transformation but are indicative of real biological variations.


```{python}

# Create separate DataFrames for each normalization method
df_original = df_merged_new[['genotype', 'unique_id', 'titer']].copy()
df_original['normalization_method'] = 'Original'

df_direct = df_merged_new[['genotype', 'unique_id', 'normalized_titer_direct_sub']].copy()
df_direct.rename(columns={'normalized_titer_direct_sub': 'titer'}, inplace=True)
df_direct['normalization_method'] = 'Direct_Subtraction'

df_ratio = df_merged_new[['genotype', 'unique_id', 'normalized_titer_ratio']].copy()
df_ratio.rename(columns={'normalized_titer_ratio': 'titer'}, inplace=True)
df_ratio['normalization_method'] = 'Ratio_Normalization'

df_zscore = df_merged_new[['genotype', 'unique_id', 'normalized_titer_zscore']].copy()
df_zscore.rename(columns={'normalized_titer_zscore': 'titer'}, inplace=True)
df_zscore['normalization_method'] = 'Z_Score_Normalization'

# Concatenate these DataFrames into a single DataFrame
df_merged = pd.concat([df_original, df_direct, df_ratio, df_zscore])

# Calculate average of averages and standard deviation for each genotype and normalization method
df_avg_of_avg = df_merged.groupby(['genotype', 'normalization_method'])['titer'].agg(['mean', 'std']).reset_index()

```




#### Barplots

```{python}




# It looks like the 'normalization_methods' list was not defined. I'll define it and re-run the plotting code.

# List of normalization methods
normalization_methods = ['Original', 'Direct_Subtraction', 'Ratio_Normalization', 'Z_Score_Normalization']

# Create the barplots
fig, axes = plt.subplots(1, 4, figsize=(20, 6))
for idx, method in enumerate(normalization_methods):
    ax = axes[idx]
    sns.barplot(x='genotype', y='mean', data=df_avg_of_avg[df_avg_of_avg['normalization_method'] == method],
                yerr=df_avg_of_avg[df_avg_of_avg['normalization_method'] == method]['std'],
                capsize=.2, ax=ax, palette='viridis')
    ax.set_title(f'Average of Averages - {method}')
    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')
    ax.set_ylabel('Average Titer')
    ax.set_xlabel('Genotype')

plt.tight_layout()
plt.show()


```

