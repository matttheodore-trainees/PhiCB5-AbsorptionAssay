---
title: "python_data_analysis"
author: "MT"
date: "`r Sys.Date()`"
output:
  word_document: default
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}


##here is what you would run in terminal to setup an environment like the rstudio environment

#conda create --name RStudio python=3.8
#conda activate RStudio
#conda install pandas matplotlib seaborn scipy statsmodels 
#conda env create -f env_config.yml

#install.packages("reticulate")


####### Is this here


# or for manual setup 

# # Set Python path
#use_python(config$python_path)
# 
# # Install Python packages (optional)
# py_install(config$packages)
# 
# 
# reticulate::py_install("pandas")
# reticulate::py_install("matplotlib")
# reticulate::py_install("seaborn")
# reticulate::py_install("scipy")
# reticulate::py_install("statsmodels")

library(reticulate)
library(pandoc)



```

### Overview 

Data Loading and Preprocessing: Loaded the data from the Excel file, checked for missing values.

Basic Summary Statistics: Calculated the mean, standard deviation, and standard error for each genotype and incubation time, grouped by date.

Control Data Extraction: Separated the control data ('bNY30a_parent') and calculated its average, standard deviation, and standard error. This control data is essential for normalizing the other data points.

Error Propagation: Calculated the normalized average and proceeded with error propagation to get the propagated standard deviation and standard error for each genotype. This was done considering the control data.

Covariance and Correlated Errors: Introduced the concept of covariance to account for the relationship between the variable and control when they are not independent. This ensures a more accurate estimate of errors.

```{r}

date()
Sys.time()
getwd()
list.files()
.libPaths()
.Library
sessionInfo()
search()
searchpaths()
R.version

```

```{r, include = FALSE}

use_condaenv("RStudio")


```






```{python}
# Importing required libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as f_oneway
import matplotlib as mpl
import statsmodels.api as sm
from statsmodels.formula.api import ols
from statsmodels.regression.mixed_linear_model import MixedLM


```

# Basic Summary Statistics and Analysis of Variation of the Data by Genotype

### Summary Statistics

```{python}



# Load the dataset from 'data_complete.xlsx'
file_path = 'Data/data_master.xlsx'
data_master = pd.read_excel(file_path)

# Calculate summary statistics
summary_stats = data_master.groupby(['date', 'genotype']).agg(
    avg_titer=pd.NamedAgg(column='titer', aggfunc=np.mean),
    stdev_titer=pd.NamedAgg(column='titer', aggfunc=np.std),
    n=pd.NamedAgg(column='titer', aggfunc='count')
).reset_index()
summary_stats['se_titer'] = summary_stats['stdev_titer'] / np.sqrt(summary_stats['n'])

# Extract control data
control_data = summary_stats[summary_stats['genotype'] == 'No Cell Control'].copy()
control_data.rename(columns={'avg_titer': 'control_avg_titer', 'stdev_titer': 'control_stdev_titer', 'se_titer': 'control_se_titer'}, inplace=True)
control_data.drop(columns=['genotype', 'n'], inplace=True)

# Merge control data with original summary statistics data based on 'date'
avg_data_with_controls = pd.merge(summary_stats, control_data, on='date')

# Calculate normalized average
avg_data_with_controls['normalized_avg'] = avg_data_with_controls['avg_titer'] / avg_data_with_controls['control_avg_titer']

```

### Error Propagation Methods
Next, let's proceed with error propagation. We'll calculate the normalized average, standard deviation, and standard error for each genotype, considering the control (bNY30a_parent) data.

For the first method, the propagation of error, we'll assume that errors in the variable and control are independent and will calculate the propagated standard deviation and error accordingly.

```{python}

# Error propagation for standard deviation
avg_data_with_controls['normalized_stdev_propagation'] = avg_data_with_controls['normalized_avg'] * np.sqrt(
    (avg_data_with_controls['stdev_titer'] / avg_data_with_controls['avg_titer']) ** 2 +
    (avg_data_with_controls['control_stdev_titer'] / avg_data_with_controls['control_avg_titer']) ** 2
)

# Standard error based on propagated standard deviation
avg_data_with_controls['normalized_se_propagation'] = avg_data_with_controls['normalized_stdev_propagation'] / np.sqrt(avg_data_with_controls['n'])


```


### Covariance and Correlated Errors
The next step involves the introduction of covariance in the error propagation. The idea here is to take into account the relationship between the variable and control when they are not independent. This is an essential step in our analysis, as ignoring the covariance could lead to inaccuracies in error estimates.

```{python}

# Covariance calculation
control_data_for_cov = data_master[data_master['genotype'] == 'No Cell Control'][['date', 'titer']]
control_data_for_cov.rename(columns={'titer': 'control_titer'}, inplace=True)
non_control_data = data_master[data_master['genotype'] != 'No Cell Control']
merged_for_cov = pd.merge(non_control_data, control_data_for_cov, on='date')
cov_data = merged_for_cov.groupby(['date', 'genotype']).apply(lambda x: np.cov(x['titer'], x['control_titer'])[0, 1]).reset_index(name='covariance')

# Merge covariance data back to normalized_data
avg_data_with_controls = pd.merge(avg_data_with_controls, cov_data, on=['date', 'genotype'], how='left')

# Calculate propagated standard deviation and standard error considering covariance
avg_data_with_controls['normalized_stdev_covariance'] = avg_data_with_controls['normalized_avg'] * np.sqrt(
    (avg_data_with_controls['stdev_titer'] / avg_data_with_controls['avg_titer']) ** 2 +
    (avg_data_with_controls['control_stdev_titer'] / avg_data_with_controls['control_avg_titer']) ** 2 -
    2 * avg_data_with_controls['covariance'] / (avg_data_with_controls['avg_titer'] * avg_data_with_controls['control_avg_titer'])
)

# Calculate standard error based on propagated standard deviation with covariance
avg_data_with_controls['normalized_se_covariance'] = avg_data_with_controls['normalized_stdev_covariance'] / np.sqrt(avg_data_with_controls['n'])



```

### Examining the differences in the stdev based on the error propogation methods

Notice that the standard deviations calculated through error propagation and error propagation with covariance are the same for the available genotypes. This suggests that the covariance term did not significantly affect the error estimates in this specific dataset.


# Interpretation of Error Propagation and Covariance Analysis

The goal here was to understand the intrinsic noise in plaque-forming unit (PFU) assays across different genotypes and on different days (biological replicates). Typically, assays like PFU could have day to day variability from various forms of errorsâ€”technical, biological, and even day-to-day variations in environmental conditions we try to control for. If we do not account for these, our interpretation of the biological relevance could be skewed.

For Error Propagation: After normalizing the PFU data by the control (bNY30a wt), I applied standard error propagation methods. This essentially adjusts the standard deviation and standard error of each genotype by accounting for the errors in both the genotype and the control.

From the Covariance: Taking it a step further, I included a covariance term in the error calculation. This is crucial because the control and other genotypes are not strictly independent; they're measured under very similar conditions and often in parallel. The covariance term adjusts for this, giving us a more accurate measure of the true error.

### Observations
Reduced Variability: After applying these rigorous statistical methods, what we observe is a more "controlled" error bar in the plots. This suggests that some of the day-to-day variations and technical errors have indeed been mitigated.


Significant Covariance: The covariance terms are not zero, confirming our initial assumption that the control and the variables are indeed not entirely independent. This validates the need for including covariance in our error model.

Plotting: Both the normalized and non-normalized data give us a rich view of the dataset. The normalized data is especially useful for comparing the effect of mutations on PFU relative to the control.

In summary, the error propagation and covariance adjustments provide us with a more robust and biologically relevant interpretation of the PFU assay data across genotypes and time points. This is crucial for downstream analyses and for drawing any high-confidence biological conclusions.

Significance Testing


```{python}

# Performing one-way ANOVA
anova_model = ols('normalized_avg ~ C(genotype)', data=avg_data_with_controls).fit()
anova_table = sm.stats.anova_lm(anova_model, typ=2)

# Performing mixed-effects model
# In this case, the 'date' is considered as a random effect
mixedlm_model = MixedLM.from_formula('normalized_avg ~ 1', groups='date', re_formula='1', data=avg_data_with_controls)
mixedlm_result = mixedlm_model.fit()

anova_table, mixedlm_result.summary()



```

```{python}

# # Filtering the data to include only the specified genotypes
# filtered_data = avg_data_with_controls[avg_data_with_controls['genotype'].isin(['bNY30a wt', 'pilAT36C'])]
# 
# # Custom order for genotypes (only the ones of interest)
# order_filtered = ['bNY30a wt', 'pilAT36C']
# 
# # Calculate p-values for the filtered dataset
# p_values_filtered = calculate_statistical_significance(filtered_data)
# 
# 
# 
# # Create individual plots with p-value significance

# Calculate summary statistics
summary_stats = data_master.groupby(['date', 'genotype']).agg(
    avg_titer=('titer', np.mean),
    stdev_titer=('titer', np.std),
    n=('titer', 'count')
).reset_index()
summary_stats['se_titer'] = summary_stats['stdev_titer'] / np.sqrt(summary_stats['n'])

# Extract control data
control_data = summary_stats[summary_stats['genotype'] == 'No Cell Control'].copy()
control_data.rename(columns={'avg_titer': 'control_avg_titer', 'stdev_titer': 'control_stdev_titer', 'se_titer': 'control_se_titer'}, inplace=True)
control_data.drop(columns=['genotype', 'n'], inplace=True)

# Merge control data with original summary statistics data based on 'date'
avg_data_with_controls = pd.merge(summary_stats, control_data, on='date')

# Calculate normalized average
avg_data_with_controls['normalized_avg'] = avg_data_with_controls['avg_titer'] / avg_data_with_controls['control_avg_titer']

# Error propagation for standard deviation
avg_data_with_controls['normalized_stdev_propagation'] = avg_data_with_controls['normalized_avg'] * np.sqrt(
    (avg_data_with_controls['stdev_titer'] / avg_data_with_controls['avg_titer']) ** 2 +
    (avg_data_with_controls['control_stdev_titer'] / avg_data_with_controls['control_avg_titer']) ** 2
)

# Standard error based on propagated standard deviation
avg_data_with_controls['normalized_se_propagation'] = avg_data_with_controls['normalized_stdev_propagation'] / np.sqrt(avg_data_with_controls['n'])

# Performing one-way ANOVA
anova_model = ols('normalized_avg ~ C(genotype)', data=avg_data_with_controls).fit()
anova_table = sm.stats.anova_lm(anova_model, typ=2)

# Performing mixed-effects model
# In this case, the 'date' is considered as a random effect
mixedlm_model = MixedLM.from_formula('normalized_avg ~ 1', groups='date', re_formula='1', data=avg_data_with_controls)
mixedlm_result = mixedlm_model.fit()

anova_tablemixedlm_result.summary()

```

```{python}
# Define the custom theme
my_theme = {
    'font.family': 'Arial',
    'axes.titlesize': 7,
    'axes.titleweight': 'bold',
    'axes.labelsize': 6,
    'xtick.labelsize': 5,
    'ytick.labelsize': 5,
    'axes.grid': False,
    'figure.figsize': (70 / 25.4, 200 / 25.4)  # Convert mm to inches
}

```


```{python}
# Create individual plots with p-value significance

# Plot: Normalized averages and propagated standard deviations with covariance for filtered genotypes
fig_filtered, ax_filtered = plt.subplots(figsize=(12, 8))
sns.barplot(x='genotype', y='normalized_avg', data=filtered_data, ax=ax_filtered, order=ordered_genotypes, ci=None)
ax_filtered.errorbar(x=np.arange(len(ordered_genotypes)), 
                         y=filtered_data.groupby('genotype')['normalized_avg'].mean()[ordered_genotypes], 
                         yerr=filtered_data.groupby('genotype')['normalized_stdev_covariance'].mean()[ordered_genotypes], 
                         fmt='o', color='black', label='Propagated Std Dev with Covariance')
sns.stripplot(x='genotype', y='normalized_avg', data=filtered_data, ax=ax_filtered, color='black', alpha=0.5, order=ordered_genotypes)
ax_filtered.set_title('Normalized PFU (Plaque Forming Units) by Selected Genotypes (Error Propagation with Covariance)')
ax_filtered.set_xlabel('Genotype')
ax_filtered.set_ylabel('PFU (Plaque Forming Units)')

# Function to add asterisks for p-value significance
def add_asterisks(ax, p_values, y_max, order):
    for i, (genotype, p) in enumerate(p_values):
        significance = ''
        if p < 0.05:
            significance = '*'
        if p < 0.01:
            significance = '**'
        if p < 0.001:
            significance = '***'
        ax.text(order.index(genotype), y_max, significance, ha='center')

add_asterisks(ax_filtered, p_values, filtered_data['normalized_avg'].max() * 1.05, ordered_genotypes)
plt.show()



```


```{r}

py$average_data_with_controls



```

